# Volume.GL

#### Volume.GL is an OpenGL viewer that enables editing and retouching of images using depth-maps. The depth maps are generated by a state of the art approach using a CNN (Convolutional Neural Network) as shown in [this paper](https://cs.nyu.edu/~deigen/depth/). Volume ueses these depth-maps to enable the addition of depth of field and color retouching for the foreground/background.
1. [Demo Video](https://www.youtube.com/watch?v=CAsy_jm85ZY)
1. [Features](#features)
1. [Dependencies](#dependencies)
1. [Future Development](#future-work)

![Editor](https://github.com/NYUCG2017/assignment-4-juniorxsound/blob/master/resources/editor.gif)

## Features

- #### Image and Depth-map viewer

![Viewer](https://github.com/NYUCG2017/assignment-4-juniorxsound/blob/master/resources/depthmap.gif)

- #### Depth of field - switchable between foreground and background

![Depth of Field](https://github.com/NYUCG2017/assignment-4-juniorxsound/blob/master/resources/dof.gif)

- #### Color retouching  - seperate coloring for foreground and background

![Color](https://github.com/NYUCG2017/assignment-4-juniorxsound/blob/master/resources/color.gif)

## Dependencies
- [GLFW](https://github.com/glfw/glfw)
- [GLEW](https://github.com/nigels-com/glew)
- [Eigen](https://github.com/libigl/eigen)
- [nanogui](https://github.com/wjakob/nanogui)

> Tested on macOS (10.13.2) using CMake (3.10.0)

## Future Work
1. Implement the same functionality in a mobile application (GLKit, iOS)
1. Use coreml-tools to convert the ML model so it could predict on an iOS device
1. Add more "depth-filters" that could be used (e.g keying out backgrounds)
